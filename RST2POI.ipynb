{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_hub as hub\n",
    "import tensorflow as tf\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Barcelona (RST) -> Paris (POI)\n",
    "# NewYork (RST) -> Paris (POI)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Obtener los ejemplos para entrenar el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(city_r, city_p):\n",
    "    # Obtener el conjunto de datos para entrenar (comieron en r y fueron a p)\n",
    "    top_n_pois = 50\n",
    "\n",
    "    city_r = city_r.lower().replace(\" \", \"\")\n",
    "    city_p = city_p.lower().replace(\" \", \"\")\n",
    "\n",
    "    reviews_r_path = f\"out/{city_r}/restaurants/reviews.pkl\"\n",
    "    reviews_p_path = f\"out/{city_p}/pois/reviews.pkl\"\n",
    "\n",
    "    reviews_r = pd.read_pickle(reviews_r_path)\n",
    "    reviews_p = pd.read_pickle(reviews_p_path)\n",
    "\n",
    "    reviews_r = reviews_r[reviews_r[\"userId\"]!=-1]\n",
    "    reviews_p = reviews_p[reviews_p[\"userId\"]!=-1]\n",
    "\n",
    "    # Quedarse con los POIs más populares\n",
    "    reviews_p_popular = reviews_p.groupby(\"itemId\")[\"itemId\"].count().sort_values(ascending=False).head(top_n_pois).index.values\n",
    "    reviews_p = reviews_p[reviews_p[\"itemId\"].isin(reviews_p_popular)]\n",
    "\n",
    "    r_data = set(reviews_r[\"userId\"].unique())\n",
    "    p_data = set(reviews_p[\"userId\"].unique())\n",
    "\n",
    "    common_users = r_data.intersection(p_data)\n",
    "\n",
    "    # ToDo: ¿Por que hay menos usuarios en el conjunto users.pkl que en reviews.pkl?\n",
    "    # ToDo: En R, tienen que ser solo los comunes???\n",
    "    reviews_r = reviews_r.loc[reviews_r[\"userId\"].isin(common_users)]\n",
    "    reviews_p = reviews_p.loc[reviews_p[\"userId\"].isin(common_users)]\n",
    "\n",
    "    out_data = []\n",
    "\n",
    "    for rst_id, rst_data in reviews_r.groupby(\"itemId\"):\n",
    "        rst_users = rst_data[\"userId\"].unique()\n",
    "        poi_revws = reviews_p.loc[reviews_p[\"userId\"].isin(rst_users)]\n",
    "        poi_revws = poi_revws.groupby(\"userId\")[\"itemId\"].unique().reset_index()\n",
    "        # ToDo: Ojo, que los usuarios de r van a más de un POI en p\n",
    "        poiId, times = np.unique(np.concatenate(poi_revws[\"itemId\"].values), return_counts=True)\n",
    "\n",
    "        print(rst_id, len(rst_users), poiId )\n",
    "\n",
    "    return reviews_r, reviews_p\n",
    "\n",
    "dataset = get_data(\"barcelona\", \"paris\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Formas de codificar un restaurante por sus fotos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▋         | 43/671 [00:10<02:40,  3.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "out/gijon/restaurants/images/sd/1640774/543354041/0000.jpg\n",
      "OpenCV(4.5.5) /io/opencv/modules/imgproc/src/color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cvtColor'\n",
      "\n",
      "out/gijon/restaurants/images/sd/1640774/505639455/0000.jpg\n",
      "OpenCV(4.5.5) /io/opencv/modules/imgproc/src/color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cvtColor'\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "zero-dimensional arrays cannot be concatenated",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[30], line 69\u001b[0m\n\u001b[1;32m     66\u001b[0m     res \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame(res, columns\u001b[39m=\u001b[39m[\u001b[39m\"\u001b[39m\u001b[39mitemId\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mname\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mn_images\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mn_reviews\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mitem_encoding\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[1;32m     67\u001b[0m     \u001b[39mreturn\u001b[39;00m res\n\u001b[0;32m---> 69\u001b[0m dataset \u001b[39m=\u001b[39m encode_items(\u001b[39m\"\u001b[39;49m\u001b[39mgijon\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m     70\u001b[0m \u001b[39mprint\u001b[39m(dataset)\n",
      "Cell \u001b[0;32mIn[30], line 61\u001b[0m, in \u001b[0;36mencode_items\u001b[0;34m(city, method, category)\u001b[0m\n\u001b[1;32m     59\u001b[0m     img_enc \u001b[39m=\u001b[39m get_image_encoding(path)\n\u001b[1;32m     60\u001b[0m     img_mtx\u001b[39m.\u001b[39mappend(img_enc)\n\u001b[0;32m---> 61\u001b[0m img_mtx \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49mconcatenate(img_mtx)\n\u001b[1;32m     62\u001b[0m encodings \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mpredict(img_mtx, verbose\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n\u001b[1;32m     63\u001b[0m ienc \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mmean(encodings, \u001b[39m0\u001b[39m)\n",
      "File \u001b[0;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mconcatenate\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: zero-dimensional arrays cannot be concatenated"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "def get_image_encoding(path):\n",
    "    try:\n",
    "        # Carga la imagen desde el path.\n",
    "        img = cv2.imread(path)\n",
    "        # BGR a RGB\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        # Normaliza la imagen entre -1 y 1.\n",
    "        img = (img / 127.5) - 1\n",
    "        # Redimensiona la imagen a 150x150 píxeles.\n",
    "        img = cv2.resize(img, (150, 150))\n",
    "        # Agrega una dimensión adicional para el batch.\n",
    "        img = np.expand_dims(img, axis=0)\n",
    "    except Exception as e:\n",
    "        print(path)\n",
    "        print(e)\n",
    "    return img\n",
    "\n",
    "def encode_items(city, method=\"ImageNet\", category=\"restaurants\"):\n",
    "    \"\"\"Codificar cada item haciendo una media de sus imágenes\"\"\"\n",
    "    # Cargar datos\n",
    "    city = city.lower().replace(\" \", \"\")\n",
    "    city_path = f\"out/{city}/{category}\"\n",
    "    items_path = f\"{city_path}/items.pkl\"\n",
    "    reviews_path = f\"{city_path}/reviews.pkl\"\n",
    "    items = pd.read_pickle(items_path)\n",
    "    reviews = pd.read_pickle(reviews_path)\n",
    "\n",
    "    # Combinar reviews e items\n",
    "    reviews = reviews.merge(items[[\"itemId\", \"name\"]], on=\"itemId\", how=\"left\")\n",
    "    reviews[\"n_images\"] = reviews[\"images\"].apply(lambda x: len(x))\n",
    "\n",
    "    # Solo items con imágenes\n",
    "    reviews = reviews.loc[reviews[\"n_images\"]>0]\n",
    "\n",
    "    # Seleccionar el encoder\n",
    "    encoder = None\n",
    "    if method == \"ImageNet\":\n",
    "        encoder = tf.keras.Sequential([hub.KerasLayer(\"https://tfhub.dev/google/imagenet/efficientnet_v2_imagenet1k_m/feature_vector/2\", trainable=False)])\n",
    "        encoder.build([None, 150, 150, 3]) # Batch input shape.\n",
    "    elif method == \"CLIP\": \n",
    "        encoder = None\n",
    "    else: \n",
    "        raise ValueError # Añadir SemPic??\n",
    "\n",
    "    # Crear, para cada item, los vectores a partir de sus imágenes\n",
    "    res = []\n",
    "    for iid, idata in tqdm(reviews.groupby(\"itemId\")):\n",
    "        iname = idata[\"name\"].unique()[0]\n",
    "\n",
    "        # Quedarse solo con reviews con imágenes y explotar los vectores de imágenes\n",
    "        idata_images = idata.explode(\"images\")\n",
    "        idata_images[\"image_id\"] = idata_images.groupby([\"itemId\", \"reviewId\"]).cumcount()\n",
    "        idata_images = idata_images.rename(columns={\"images\": \"image_url\", \"image\": \"image\"})\n",
    "\n",
    "        idata_image_paths = idata_images.apply(lambda x: f'{city_path}/images/sd/{iid}/{x[\"reviewId\"]}/{x[\"image_id\"]:04d}.jpg',1).values\n",
    "\n",
    "        img_mtx = []\n",
    "        for path in idata_image_paths:\n",
    "            img_enc = get_image_encoding(path)\n",
    "            img_mtx.append(img_enc)\n",
    "        img_mtx = np.concatenate(img_mtx)\n",
    "        encodings = model.predict(img_mtx, verbose=0)\n",
    "        ienc = np.mean(encodings, 0)\n",
    "\n",
    "        res.append((iid, iname,  idata[\"n_images\"].sum(), len(idata), ienc))\n",
    "    res = pd.DataFrame(res, columns=[\"itemId\", \"name\", \"n_images\", \"n_reviews\", \"item_encoding\"])\n",
    "    return res\n",
    "\n",
    "dataset = encode_items(\"gijon\")\n",
    "print(dataset)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TripAdvisorDownload",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
