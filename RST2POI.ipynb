{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-06 13:09:22.717331: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-06-06 13:09:23.980709: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-06-06 13:09:26.908342: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64\n",
      "2023-06-06 13:09:26.909094: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64\n",
      "2023-06-06 13:09:26.909104: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow_hub as hub\n",
    "import tensorflow as tf\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_p_path = f\"out/gijon/restaurants/reviews.pkl\"\n",
    "reviews = pd.read_pickle(reviews_p_path)\n",
    "reviews.groupby(\"itemId\")[\"itemId\"].count().sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>city</th>\n",
       "      <th>$$$$</th>\n",
       "      <th>$$ - $$$</th>\n",
       "      <th>$</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gijon</td>\n",
       "      <td>19</td>\n",
       "      <td>436</td>\n",
       "      <td>132</td>\n",
       "      <td>253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>barcelona</td>\n",
       "      <td>286</td>\n",
       "      <td>4480</td>\n",
       "      <td>2196</td>\n",
       "      <td>2568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>warsaw</td>\n",
       "      <td>92</td>\n",
       "      <td>1373</td>\n",
       "      <td>891</td>\n",
       "      <td>1250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>budapest</td>\n",
       "      <td>114</td>\n",
       "      <td>1510</td>\n",
       "      <td>1041</td>\n",
       "      <td>1204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hamburg</td>\n",
       "      <td>122</td>\n",
       "      <td>1482</td>\n",
       "      <td>580</td>\n",
       "      <td>1103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>vienna</td>\n",
       "      <td>124</td>\n",
       "      <td>2287</td>\n",
       "      <td>794</td>\n",
       "      <td>1596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>bucharest</td>\n",
       "      <td>98</td>\n",
       "      <td>1048</td>\n",
       "      <td>457</td>\n",
       "      <td>1011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>newyorkcity</td>\n",
       "      <td>473</td>\n",
       "      <td>3776</td>\n",
       "      <td>2116</td>\n",
       "      <td>3766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>paris</td>\n",
       "      <td>729</td>\n",
       "      <td>8881</td>\n",
       "      <td>2988</td>\n",
       "      <td>4339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>rome</td>\n",
       "      <td>334</td>\n",
       "      <td>5134</td>\n",
       "      <td>3365</td>\n",
       "      <td>2816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>madrid</td>\n",
       "      <td>335</td>\n",
       "      <td>5405</td>\n",
       "      <td>2188</td>\n",
       "      <td>3528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>berlin</td>\n",
       "      <td>157</td>\n",
       "      <td>3150</td>\n",
       "      <td>1786</td>\n",
       "      <td>2359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>london</td>\n",
       "      <td>657</td>\n",
       "      <td>9487</td>\n",
       "      <td>4363</td>\n",
       "      <td>6759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>istanbul</td>\n",
       "      <td>453</td>\n",
       "      <td>3100</td>\n",
       "      <td>1768</td>\n",
       "      <td>11172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>moscow</td>\n",
       "      <td>446</td>\n",
       "      <td>5568</td>\n",
       "      <td>3164</td>\n",
       "      <td>6327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>st.petersburg</td>\n",
       "      <td>231</td>\n",
       "      <td>3123</td>\n",
       "      <td>2640</td>\n",
       "      <td>5445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>athens</td>\n",
       "      <td>82</td>\n",
       "      <td>1144</td>\n",
       "      <td>990</td>\n",
       "      <td>946</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             city $$$$ $$ - $$$     $       \n",
       "0           gijon   19      436   132    253\n",
       "1       barcelona  286     4480  2196   2568\n",
       "2          warsaw   92     1373   891   1250\n",
       "3        budapest  114     1510  1041   1204\n",
       "4         hamburg  122     1482   580   1103\n",
       "5          vienna  124     2287   794   1596\n",
       "6       bucharest   98     1048   457   1011\n",
       "7     newyorkcity  473     3776  2116   3766\n",
       "8           paris  729     8881  2988   4339\n",
       "9            rome  334     5134  3365   2816\n",
       "10         madrid  335     5405  2188   3528\n",
       "11         berlin  157     3150  1786   2359\n",
       "12         london  657     9487  4363   6759\n",
       "13       istanbul  453     3100  1768  11172\n",
       "14         moscow  446     5568  3164   6327\n",
       "15  st.petersburg  231     3123  2640   5445\n",
       "16         athens   82     1144   990    946"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cities = [\"Gijon\", \"Barcelona\", \"Warsaw\", \"Budapest\", \"Hamburg\", \"Vienna\", \"Bucharest\", \"New York City\", \"Paris\", \"Rome\", \"Madrid\", \"Berlin\", \"London\", \"Istanbul\", \"Moscow\", \"St. Petersburg\", \"Athens\"]\n",
    "\n",
    "res = []\n",
    "\n",
    "for c in cities:\n",
    "    c = c.lower().replace(\" \", \"\")\n",
    "    reviews_p_path = f\"out/{c}/restaurants/items.pkl\"\n",
    "    reviews = pd.read_pickle(reviews_p_path)\n",
    "    a,b = np.unique(reviews[\"priceInterval\"], return_counts=True)\n",
    "    city_data = dict(zip(a,b))\n",
    "    city_data[\"city\"] = c\n",
    "    res.append(pd.DataFrame(city_data, index=[0]).values.tolist()[0])\n",
    "    \n",
    "pd.DataFrame(res, columns=[list(city_data.keys())])[list(city_data.keys())[::-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Barcelona (RST) -> Paris (POI)\n",
    "# NewYork (RST) -> Paris (POI)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obtener los ejemplos para entrenar el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(city_r, city_p):\n",
    "    # Obtener el conjunto de datos para entrenar (comieron en r y fueron a p)\n",
    "    top_n_pois = 50\n",
    "\n",
    "    city_r = city_r.lower().replace(\" \", \"\")\n",
    "    city_p = city_p.lower().replace(\" \", \"\")\n",
    "\n",
    "    reviews_r_path = f\"out/{city_r}/restaurants/reviews.pkl\"\n",
    "    reviews_p_path = f\"out/{city_p}/pois/reviews.pkl\"\n",
    "\n",
    "    reviews_r = pd.read_pickle(reviews_r_path)\n",
    "    reviews_p = pd.read_pickle(reviews_p_path)\n",
    "\n",
    "    reviews_r = reviews_r[reviews_r[\"userId\"]!=-1]\n",
    "    reviews_p = reviews_p[reviews_p[\"userId\"]!=-1]\n",
    "\n",
    "    # Quedarse con los POIs más populares\n",
    "    reviews_p_popular = reviews_p.groupby(\"itemId\")[\"itemId\"].count().sort_values(ascending=False).head(top_n_pois).index.values\n",
    "    reviews_p = reviews_p[reviews_p[\"itemId\"].isin(reviews_p_popular)]\n",
    "\n",
    "    r_data = set(reviews_r[\"userId\"].unique())\n",
    "    p_data = set(reviews_p[\"userId\"].unique())\n",
    "\n",
    "    common_users = r_data.intersection(p_data)\n",
    "\n",
    "    # ToDo: ¿Por que hay menos usuarios en el conjunto users.pkl que en reviews.pkl?\n",
    "    # ToDo: En R, tienen que ser solo los comunes???\n",
    "    reviews_r = reviews_r.loc[reviews_r[\"userId\"].isin(common_users)]\n",
    "    reviews_p = reviews_p.loc[reviews_p[\"userId\"].isin(common_users)]\n",
    "\n",
    "    out_data = []\n",
    "\n",
    "    for rst_id, rst_data in reviews_r.groupby(\"itemId\"):\n",
    "        rst_users = rst_data[\"userId\"].unique()\n",
    "        poi_revws = reviews_p.loc[reviews_p[\"userId\"].isin(rst_users)]\n",
    "        poi_revws = poi_revws.groupby(\"userId\")[\"itemId\"].unique().reset_index()\n",
    "        # ToDo: Ojo, que los usuarios de r van a más de un POI en p\n",
    "        poiId, times = np.unique(np.concatenate(poi_revws[\"itemId\"].values), return_counts=True)\n",
    "\n",
    "        print(rst_id, len(rst_users), poiId )\n",
    "\n",
    "    return reviews_r, reviews_p\n",
    "\n",
    "dataset = get_data(\"barcelona\", \"paris\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Formas de codificar un restaurante por sus fotos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        itemId                        name  n_images  n_reviews   \n",
      "0       693801                   Bar Celta       203        107  \\\n",
      "1       693822          Restaurante Manolo        18         10   \n",
      "2       693855                   Can Lluis        80         35   \n",
      "3       693967                   Elisabets       316        143   \n",
      "4       697396                    7 Portes      2676       1172   \n",
      "...        ...                         ...       ...        ...   \n",
      "6509  25338856             Velvet Room BCN         4          1   \n",
      "6510  25361641       MiMi Tapas Restaurant         6          4   \n",
      "6511  25362471             Mimi Restaurant         7          3   \n",
      "6512  25363246           Fonda Can Portell         4          1   \n",
      "6513  25386551  McDonalds - Som Multiespai         4          1   \n",
      "\n",
      "                                          item_encoding  \n",
      "0     [0.0011015198, -0.045368917, 0.06882931, -0.06...  \n",
      "1     [-0.08390628, 0.0139746815, 0.18736298, -0.102...  \n",
      "2     [-0.049717955, -0.06934771, 0.1684383, -0.0441...  \n",
      "3     [-0.037663653, -0.07932761, 0.13506116, -0.127...  \n",
      "4     [-0.06365619, -0.0982724, 0.16331768, -0.06829...  \n",
      "...                                                 ...  \n",
      "6509  [-0.13259922, 0.07872795, 0.2050268, -0.180780...  \n",
      "6510  [-0.11273998, -0.046104856, 0.22787046, -0.168...  \n",
      "6511  [-0.009020974, 0.010424785, 0.006621013, 0.339...  \n",
      "6512  [-0.071157925, -0.10712695, -0.091845095, 0.06...  \n",
      "6513  [-0.24776119, 0.18385397, -0.068481326, 0.0473...  \n",
      "\n",
      "[6514 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "def read_image(path):\n",
    "    try:\n",
    "        # Carga la imagen desde el path.\n",
    "        img = cv2.imread(path)\n",
    "        # BGR a RGB\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        # Normaliza la imagen entre -1 y 1.\n",
    "        img = (img / 127.5) - 1\n",
    "        # Redimensiona la imagen a 150x150 píxeles.\n",
    "        img = cv2.resize(img, (150, 150))\n",
    "        # Agrega una dimensión adicional para el batch.\n",
    "        img = np.expand_dims(img, axis=0)\n",
    "    except Exception as e:\n",
    "        print(path)\n",
    "        print(e)\n",
    "    return img\n",
    "\n",
    "def encode_items(city, method=\"ImageNet\", category=\"restaurants\", min_images=4):\n",
    "    \"\"\"Codificar cada item haciendo una media de sus imágenes\"\"\"\n",
    "    out_file = f\"{city}_itm_emb.pkl\"\n",
    "\n",
    "    if not os.path.exists(out_file):\n",
    "        # Cargar datos\n",
    "        city = city.lower().replace(\" \", \"\")\n",
    "        city_path = f\"out/{city}/{category}\"\n",
    "        items_path = f\"{city_path}/items.pkl\"\n",
    "        reviews_path = f\"{city_path}/reviews.pkl\" # OJO QUE HAY DUPLICADOS\n",
    "        items = pd.read_pickle(items_path)\n",
    "        reviews = pd.read_pickle(reviews_path)\n",
    "\n",
    "        # Combinar reviews e items\n",
    "        reviews = reviews.merge(items[[\"itemId\", \"name\"]], on=\"itemId\", how=\"left\")\n",
    "        reviews[\"n_images\"] = reviews[\"images\"].apply(lambda x: len(x))\n",
    "\n",
    "        # Solo items con imágenes\n",
    "        reviews = reviews.loc[reviews[\"n_images\"]>0]\n",
    "\n",
    "        # Seleccionar el encoder\n",
    "        encoder = None\n",
    "        if method == \"ImageNet\":\n",
    "            encoder = tf.keras.Sequential([hub.KerasLayer(\"https://tfhub.dev/google/imagenet/efficientnet_v2_imagenet1k_m/feature_vector/2\", trainable=False)])\n",
    "            encoder.build([None, 150, 150, 3]) # Batch input shape.\n",
    "        elif method == \"CLIP\": \n",
    "            encoder = None\n",
    "        else: \n",
    "            raise ValueError # Añadir SemPic??\n",
    "\n",
    "        # Crear, para cada item, los vectores a partir de sus imágenes\n",
    "        res = []\n",
    "        for iid, idata in tqdm(reviews.groupby(\"itemId\")):\n",
    "            iname = idata[\"name\"].unique()[0]\n",
    "\n",
    "            if idata[\"n_images\"].sum()<min_images: continue\n",
    "\n",
    "            # Quedarse solo con reviews con imágenes y explotar los vectores de imágenes\n",
    "            idata_images = idata.explode(\"images\").drop_duplicates(\"reviewId\")\n",
    "            idata_images[\"image_id\"] = idata_images.groupby([\"itemId\", \"reviewId\"]).cumcount()\n",
    "            idata_images = idata_images.rename(columns={\"images\": \"image_url\", \"image\": \"image\"})\n",
    "\n",
    "            idata_image_paths = idata_images.apply(lambda x: f'{city_path}/images/sd/{iid}/{x[\"reviewId\"]}/{x[\"image_id\"]:04d}.jpg',1).values\n",
    "\n",
    "            img_mtx = []\n",
    "            for path in idata_image_paths:\n",
    "                img_data = read_image(path)\n",
    "                img_mtx.append(img_data)\n",
    "            img_mtx = np.concatenate(img_mtx)\n",
    "            encodings = encoder.predict(img_mtx, verbose=0)\n",
    "            ienc = np.mean(encodings, 0)\n",
    "\n",
    "            res.append((iid, iname,  idata[\"n_images\"].sum(), len(idata), ienc))\n",
    "        res = pd.DataFrame(res, columns=[\"itemId\", \"name\", \"n_images\", \"n_reviews\", \"item_encoding\"])\n",
    "        res.to_pickle(f\"{city}_itm_emb.pkl\")\n",
    "    else:\n",
    "        res = pd.read_pickle(out_file)\n",
    "    return res\n",
    "\n",
    "dataset = encode_items(\"barcelona\")\n",
    "print(dataset)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### t-SNE de restaurantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "\n",
    "tsne = TSNE(n_components=2)\n",
    "data_2d = tsne.fit_transform(np.array(dataset['item_encoding'].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bokeh.models import LinearColorMapper\n",
    "from bokeh.models import ColumnDataSource\n",
    "#from bokeh.plotting import figure, show\n",
    "#from bokeh.resources import INLINE\n",
    "\n",
    "#output_notebook(INLINE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data_2d' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m source \u001b[39m=\u001b[39m ColumnDataSource(data\u001b[39m=\u001b[39m\u001b[39mdict\u001b[39m(\n\u001b[0;32m----> 2\u001b[0m     x\u001b[39m=\u001b[39mdata_2d[:,\u001b[39m0\u001b[39m],\n\u001b[1;32m      3\u001b[0m     y\u001b[39m=\u001b[39mdata_2d[:,\u001b[39m1\u001b[39m],\n\u001b[1;32m      4\u001b[0m     name\u001b[39m=\u001b[39mdataset[\u001b[39m'\u001b[39m\u001b[39mname\u001b[39m\u001b[39m'\u001b[39m],\n\u001b[1;32m      5\u001b[0m     color\u001b[39m=\u001b[39mdataset[\u001b[39m'\u001b[39m\u001b[39mn_images\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m      6\u001b[0m ))\n\u001b[1;32m      8\u001b[0m TOOLTIPS \u001b[39m=\u001b[39m [(\u001b[39m\"\u001b[39m\u001b[39mName\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m@name\u001b[39m\u001b[39m\"\u001b[39m),(\u001b[39m\"\u001b[39m\u001b[39mn_images\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m@color\u001b[39m\u001b[39m\"\u001b[39m)]\n\u001b[1;32m      9\u001b[0m p \u001b[39m=\u001b[39m figure(width\u001b[39m=\u001b[39m\u001b[39m1000\u001b[39m, height\u001b[39m=\u001b[39m\u001b[39m1000\u001b[39m, tooltips\u001b[39m=\u001b[39mTOOLTIPS)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'data_2d' is not defined"
     ]
    }
   ],
   "source": [
    "source = ColumnDataSource(data=dict(\n",
    "    x=data_2d[:,0],\n",
    "    y=data_2d[:,1],\n",
    "    name=dataset['name'],\n",
    "    color=dataset['n_images']\n",
    "))\n",
    "\n",
    "TOOLTIPS = [(\"Name\", \"@name\"),(\"n_images\", \"@color\")]\n",
    "p = figure(width=1000, height=1000, tooltips=TOOLTIPS)\n",
    "\n",
    "lc = LinearColorMapper(palette=\"Greys256\", low=dataset['n_images'].max(), high=dataset['n_images'].min())\n",
    "p.circle('x', 'y', source=source, size=10, fill_color={\"field\": \"color\", \"transform\": lc})\n",
    "show(p)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TripAdvisorDownload",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
